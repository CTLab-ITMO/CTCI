{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a93509566f2ac08",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-03-30T10:55:59.237473Z",
     "start_time": "2024-03-30T10:55:55.984517Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import torch\n",
    "\n",
    "from src.models.yolov8_detector.yolo import load_yolov8_detector\n",
    "from src.models.sam.sam import load_sam_predictor, segment_images_from_folder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64138b686e0e43da",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94927a50811630a0",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-29T15:59:19.275162Z",
     "start_time": "2024-03-29T15:59:19.260148Z"
    }
   },
   "outputs": [],
   "source": [
    "DATA_DIR = r\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "89bc4965",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-29T15:59:19.291177Z",
     "start_time": "2024-03-29T15:59:19.276163Z"
    }
   },
   "outputs": [],
   "source": [
    "def filter_hidden_folders(folder):\n",
    "    if folder[0] == '.':\n",
    "        return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c6c1ad79608d7671",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-29T15:59:19.307192Z",
     "start_time": "2024-03-29T15:59:19.293179Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "['F1_1_2_1.ts-frames_frame-535.png',\n 'F1_1_3_1.ts-frames_frame-815.png',\n 'F1_1_3_2.ts-frames_frame-1710.png',\n 'F1_1_4_1.ts-frames_frame-5.png',\n 'F1_1_5_2.ts-frames_frame-450.png']"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folders_list = os.listdir(DATA_DIR)\n",
    "folders_list = list(filter(filter_hidden_folders, folders_list))\n",
    "folders_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f6586033c89806ea",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-28T13:15:44.604653Z",
     "start_time": "2024-03-28T13:15:44.589639Z"
    }
   },
   "outputs": [],
   "source": [
    "def count_images(image_folder_path):\n",
    "    images_num = len(os.listdir(image_folder_path))\n",
    "    return images_num\n",
    "\n",
    "def summarize_folders(data_dir, folders_list):\n",
    "    folders_info = {}\n",
    "    images_sum = 0\n",
    "    \n",
    "    for folder in folders_list:\n",
    "        images_num = count_images(os.path.join(data_dir, folder))\n",
    "        folders_info[folder] = images_num\n",
    "        images_sum += images_num\n",
    "        \n",
    "    print(f\"There is {images_sum} images:\")\n",
    "    for folder in folders_info.keys():\n",
    "        print(f\"\\t{folder} folder has {folders_info[folder]} images\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5a6d902ee413c57d",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-28T13:15:45.357338Z",
     "start_time": "2024-03-28T13:15:44.605654Z"
    }
   },
   "outputs": [
    {
     "ename": "NotADirectoryError",
     "evalue": "[WinError 267] Неверно задано имя папки: 'D:\\\\vscode\\\\ctci\\\\CTCI\\\\data\\\\paper images\\\\F1_1_2_1.ts-frames_frame-535.png'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNotADirectoryError\u001B[0m                        Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[6], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43msummarize_folders\u001B[49m\u001B[43m(\u001B[49m\u001B[43mDATA_DIR\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfolders_list\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[5], line 10\u001B[0m, in \u001B[0;36msummarize_folders\u001B[1;34m(data_dir, folders_list)\u001B[0m\n\u001B[0;32m      7\u001B[0m images_sum \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[0;32m      9\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m folder \u001B[38;5;129;01min\u001B[39;00m folders_list:\n\u001B[1;32m---> 10\u001B[0m     images_num \u001B[38;5;241m=\u001B[39m \u001B[43mcount_images\u001B[49m\u001B[43m(\u001B[49m\u001B[43mos\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpath\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mjoin\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata_dir\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfolder\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     11\u001B[0m     folders_info[folder] \u001B[38;5;241m=\u001B[39m images_num\n\u001B[0;32m     12\u001B[0m     images_sum \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m images_num\n",
      "Cell \u001B[1;32mIn[5], line 2\u001B[0m, in \u001B[0;36mcount_images\u001B[1;34m(image_folder_path)\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcount_images\u001B[39m(image_folder_path):\n\u001B[1;32m----> 2\u001B[0m     images_num \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlen\u001B[39m(\u001B[43mos\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlistdir\u001B[49m\u001B[43m(\u001B[49m\u001B[43mimage_folder_path\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[0;32m      3\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m images_num\n",
      "\u001B[1;31mNotADirectoryError\u001B[0m: [WinError 267] Неверно задано имя папки: 'D:\\\\vscode\\\\ctci\\\\CTCI\\\\data\\\\paper images\\\\F1_1_2_1.ts-frames_frame-535.png'"
     ]
    }
   ],
   "source": [
    "summarize_folders(DATA_DIR, folders_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d59d65d1c78526d",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# SAM+YOLO Labeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f94afe22ff89b906",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Yolo detector:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "63db24b519d2ae6b",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-29T15:59:20.390175Z",
     "start_time": "2024-03-29T15:59:19.308192Z"
    }
   },
   "outputs": [],
   "source": [
    "custom_yolo_checkpoint_path = r\"\"\n",
    "detector = load_yolov8_detector(custom_yolo_checkpoint_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa34121c96a97dbc",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "SAM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ac44a246ef8971ac",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-29T16:03:15.629917Z",
     "start_time": "2024-03-29T16:03:14.928280Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictor's device is cpu\n"
     ]
    }
   ],
   "source": [
    "sam_checkpoint = r\"\"\n",
    "model_type = \"vit_h\"\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "predictor = load_sam_predictor(checkpoint_path=sam_checkpoint, model_type=model_type, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "486276d9a8073c3b",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "folder = folders_list[3]\n",
    "folder\n",
    "target_length=1024\n",
    "narrowing = 0.20\n",
    "erode_iterations = 1"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-29T16:14:30.997566Z",
     "start_time": "2024-03-29T16:14:30.979549Z"
    }
   },
   "id": "313649a196be72"
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "source_dir = os.path.join(DATA_DIR, folder)\n",
    "output_dir = os.path.join(DATA_DIR, folder + \"_masks\")\n",
    "\n",
    "processes_num = 2"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-29T16:14:31.298840Z",
     "start_time": "2024-03-29T16:14:31.290832Z"
    }
   },
   "id": "e3c232abf2727423"
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "944f6650",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-29T16:15:23.609369Z",
     "start_time": "2024-03-29T16:15:22.178069Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image F1_1_2_1.ts-frames_frame-535.png\n",
      "0: 608x800 23 bubbles, 267.2ms\n",
      "Speed: 2.0ms preprocess, 267.2ms inference, 1.0ms postprocess per image at shape (1, 3, 608, 800)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:01<?, ?it/s]\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "set_torch_image input must be BCHW with long side 1024.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAssertionError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[23], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43msegment_images_from_folder\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m      2\u001B[0m \u001B[43m    \u001B[49m\u001B[43msource_dir\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      3\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_dir\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      4\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdetector\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpredictor\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      5\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtarget_length\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtarget_length\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      6\u001B[0m \u001B[43m    \u001B[49m\u001B[43mnarrowing\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnarrowing\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      7\u001B[0m \u001B[43m    \u001B[49m\u001B[43merode_iterations\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43merode_iterations\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      8\u001B[0m \u001B[43m    \u001B[49m\u001B[43mprocesses_num\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mprocesses_num\u001B[49m\n\u001B[0;32m      9\u001B[0m \u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\vscode\\ctci\\CTCI\\src\\models\\sam\\sam.py:275\u001B[0m, in \u001B[0;36msegment_images_from_folder\u001B[1;34m(source_dir, output_dir, detector, predictor, target_length, narrowing, erode_iterations, processes_num)\u001B[0m\n\u001B[0;32m    273\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m image_name \u001B[38;5;129;01min\u001B[39;00m tqdm(images_list):\n\u001B[0;32m    274\u001B[0m         \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mno_grad():\n\u001B[1;32m--> 275\u001B[0m             \u001B[43msegment_image_from_dir\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    276\u001B[0m \u001B[43m                \u001B[49m\u001B[43mimage_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    277\u001B[0m \u001B[43m                \u001B[49m\u001B[43mmasks_list\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    278\u001B[0m \u001B[43m                \u001B[49m\u001B[43msource_dir\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    279\u001B[0m \u001B[43m                \u001B[49m\u001B[43moutput_dir\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    280\u001B[0m \u001B[43m                \u001B[49m\u001B[43mdetector\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpredictor\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    281\u001B[0m \u001B[43m                \u001B[49m\u001B[43mtarget_length\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtarget_length\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    282\u001B[0m \u001B[43m                \u001B[49m\u001B[43mnarrowing\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnarrowing\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    283\u001B[0m \u001B[43m                \u001B[49m\u001B[43merode_iterations\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43merode_iterations\u001B[49m\n\u001B[0;32m    284\u001B[0m \u001B[43m            \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    285\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    286\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mno_grad():\n",
      "File \u001B[1;32mD:\\vscode\\ctci\\CTCI\\src\\models\\sam\\sam.py:214\u001B[0m, in \u001B[0;36msegment_image_from_dir\u001B[1;34m(image_name, masks_list, source_dir, output_dir, detector, predictor, target_length, narrowing, erode_iterations)\u001B[0m\n\u001B[0;32m    212\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mImage \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mimage_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    213\u001B[0m image \u001B[38;5;241m=\u001B[39m cv2\u001B[38;5;241m.\u001B[39mimread(os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(source_dir, image_name))\n\u001B[1;32m--> 214\u001B[0m mask \u001B[38;5;241m=\u001B[39m \u001B[43myolo_sam_segmentation\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    215\u001B[0m \u001B[43m    \u001B[49m\u001B[43mimage\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdetector\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpredictor\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    216\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtarget_length\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtarget_length\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    217\u001B[0m \u001B[43m    \u001B[49m\u001B[43mnarrowing\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnarrowing\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    218\u001B[0m \u001B[43m    \u001B[49m\u001B[43merode_iterations\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43merode_iterations\u001B[49m\n\u001B[0;32m    219\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    221\u001B[0m cv2\u001B[38;5;241m.\u001B[39mimwrite(\n\u001B[0;32m    222\u001B[0m     filename\u001B[38;5;241m=\u001B[39mos\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(output_dir, image_name),\n\u001B[0;32m    223\u001B[0m     img\u001B[38;5;241m=\u001B[39mmask\n\u001B[0;32m    224\u001B[0m )\n\u001B[0;32m    226\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mImage \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mimage_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m were segmented!\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32mD:\\vscode\\ctci\\CTCI\\src\\models\\sam\\sam.py:158\u001B[0m, in \u001B[0;36myolo_sam_segmentation\u001B[1;34m(image, detector, predictor, target_length, narrowing, erode_iterations)\u001B[0m\n\u001B[0;32m    155\u001B[0m mask_watershed \u001B[38;5;241m=\u001B[39m perform_watershed(cv2\u001B[38;5;241m.\u001B[39mcvtColor(image, cv2\u001B[38;5;241m.\u001B[39mCOLOR_BGR2GRAY))\n\u001B[0;32m    157\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(boxes) \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m--> 158\u001B[0m     masks_list \u001B[38;5;241m=\u001B[39m \u001B[43msam_segmentation\u001B[49m\u001B[43m(\u001B[49m\u001B[43mimage\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mimage\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpredictor\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpredictor\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mboxes\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mboxes\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mprompt_points\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    159\u001B[0m \u001B[43m                                  \u001B[49m\u001B[43mtarget_length\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtarget_length\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    160\u001B[0m     masks_united \u001B[38;5;241m=\u001B[39m []\n\u001B[0;32m    161\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m masks \u001B[38;5;129;01min\u001B[39;00m masks_list:\n",
      "File \u001B[1;32mD:\\vscode\\ctci\\CTCI\\src\\models\\sam\\sam.py:94\u001B[0m, in \u001B[0;36msam_segmentation\u001B[1;34m(image, predictor, boxes, prompt_points, target_length)\u001B[0m\n\u001B[0;32m     91\u001B[0m transformed_image_torch \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mas_tensor(transformed_image, device\u001B[38;5;241m=\u001B[39mdevice)\n\u001B[0;32m     92\u001B[0m transformed_image_torch \u001B[38;5;241m=\u001B[39m transformed_image_torch\u001B[38;5;241m.\u001B[39mpermute(\u001B[38;5;241m2\u001B[39m, \u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m1\u001B[39m)\u001B[38;5;241m.\u001B[39mcontiguous()[\u001B[38;5;28;01mNone\u001B[39;00m, :, :, :]\n\u001B[1;32m---> 94\u001B[0m \u001B[43mpredictor\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mset_torch_image\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m     95\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtransformed_image\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtransformed_image_torch\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     96\u001B[0m \u001B[43m    \u001B[49m\u001B[43moriginal_image_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moriginal_image_size\u001B[49m\n\u001B[0;32m     97\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     99\u001B[0m boxes \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39marray(boxes)\n\u001B[0;32m    100\u001B[0m boxes \u001B[38;5;241m=\u001B[39m transform\u001B[38;5;241m.\u001B[39mapply_boxes(boxes, (predictor\u001B[38;5;241m.\u001B[39moriginal_size[\u001B[38;5;241m0\u001B[39m], predictor\u001B[38;5;241m.\u001B[39moriginal_size[\u001B[38;5;241m1\u001B[39m]))\n",
      "File \u001B[1;32mD:\\vscode\\ctci\\CTCI\\venv\\lib\\site-packages\\torch\\utils\\_contextlib.py:115\u001B[0m, in \u001B[0;36mcontext_decorator.<locals>.decorate_context\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    112\u001B[0m \u001B[38;5;129m@functools\u001B[39m\u001B[38;5;241m.\u001B[39mwraps(func)\n\u001B[0;32m    113\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdecorate_context\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m    114\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m ctx_factory():\n\u001B[1;32m--> 115\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32mD:\\vscode\\ctci\\CTCI\\venv\\lib\\site-packages\\segment_anything\\predictor.py:82\u001B[0m, in \u001B[0;36mSamPredictor.set_torch_image\u001B[1;34m(self, transformed_image, original_image_size)\u001B[0m\n\u001B[0;32m     62\u001B[0m \u001B[38;5;129m@torch\u001B[39m\u001B[38;5;241m.\u001B[39mno_grad()\n\u001B[0;32m     63\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mset_torch_image\u001B[39m(\n\u001B[0;32m     64\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m     65\u001B[0m     transformed_image: torch\u001B[38;5;241m.\u001B[39mTensor,\n\u001B[0;32m     66\u001B[0m     original_image_size: Tuple[\u001B[38;5;28mint\u001B[39m, \u001B[38;5;241m.\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;241m.\u001B[39m],\n\u001B[0;32m     67\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m     68\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m     69\u001B[0m \u001B[38;5;124;03m    Calculates the image embeddings for the provided image, allowing\u001B[39;00m\n\u001B[0;32m     70\u001B[0m \u001B[38;5;124;03m    masks to be predicted with the 'predict' method. Expects the input\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     77\u001B[0m \u001B[38;5;124;03m        before transformation, in (H, W) format.\u001B[39;00m\n\u001B[0;32m     78\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m     79\u001B[0m     \u001B[38;5;28;01massert\u001B[39;00m (\n\u001B[0;32m     80\u001B[0m         \u001B[38;5;28mlen\u001B[39m(transformed_image\u001B[38;5;241m.\u001B[39mshape) \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m4\u001B[39m\n\u001B[0;32m     81\u001B[0m         \u001B[38;5;129;01mand\u001B[39;00m transformed_image\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m1\u001B[39m] \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m3\u001B[39m\n\u001B[1;32m---> 82\u001B[0m         \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mmax\u001B[39m(\u001B[38;5;241m*\u001B[39mtransformed_image\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m2\u001B[39m:]) \u001B[38;5;241m==\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel\u001B[38;5;241m.\u001B[39mimage_encoder\u001B[38;5;241m.\u001B[39mimg_size\n\u001B[0;32m     83\u001B[0m     ), \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mset_torch_image input must be BCHW with long side \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel\u001B[38;5;241m.\u001B[39mimage_encoder\u001B[38;5;241m.\u001B[39mimg_size\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m     84\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mreset_image()\n\u001B[0;32m     86\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moriginal_size \u001B[38;5;241m=\u001B[39m original_image_size\n",
      "\u001B[1;31mAssertionError\u001B[0m: set_torch_image input must be BCHW with long side 1024."
     ]
    }
   ],
   "source": [
    "segment_images_from_folder(\n",
    "    source_dir,\n",
    "    output_dir,\n",
    "    detector, predictor,\n",
    "    target_length=target_length,\n",
    "    narrowing=narrowing,\n",
    "    erode_iterations=erode_iterations,\n",
    "    processes_num=processes_num\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c4c2794",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-06T18:40:01.405380100Z",
     "start_time": "2024-02-06T18:40:01.404383200Z"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
