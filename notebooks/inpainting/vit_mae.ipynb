{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Imports"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1d0026f475957ac2"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-01-27T23:22:54.909829100Z",
     "start_time": "2024-01-27T23:22:51.244452Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from transformers import ViTMAEForPreTraining, AutoImageProcessor\n",
    "\n",
    "from src.vitmae.dataset import BubblesDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Device"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "934fe301790af329"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-27T23:22:54.924793400Z",
     "start_time": "2024-01-27T23:22:54.911824500Z"
    }
   },
   "id": "4b493d2579efed88"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Image Processor"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d37c58276ed3e7f1"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "image_processor_checkpoint = r\"facebook/vit-mae-base\"\n",
    "image_processor = AutoImageProcessor.from_pretrained(image_processor_checkpoint)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-27T23:22:55.367005800Z",
     "start_time": "2024-01-27T23:22:54.927785200Z"
    }
   },
   "id": "2767621dc1f259e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Dataset"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "eda34319a42f07ec"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "train_images_dir = r\"C:\\Internship\\ITMO_ML\\data\\ViTMAE\\train\"\n",
    "val_images_dir = r\"C:\\Internship\\ITMO_ML\\data\\ViTMAE\\val\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-27T23:22:55.382980500Z",
     "start_time": "2024-01-27T23:22:55.362020500Z"
    }
   },
   "id": "b558a81497c79784"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "train_dataset = BubblesDataset(images_dir=train_images_dir, image_processor=image_processor)\n",
    "val_dataset = BubblesDataset(images_dir=val_images_dir, image_processor=image_processor)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-27T23:22:55.484835400Z",
     "start_time": "2024-01-27T23:22:55.377979300Z"
    }
   },
   "id": "346fdfb01f94e240"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "batch_size_train = 96\n",
    "batch_size_val = 96\n",
    "pin_memory = True\n",
    "num_workers = 4"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-27T23:22:55.504780700Z",
     "start_time": "2024-01-27T23:22:55.487828500Z"
    }
   },
   "id": "14f878caa080ab96"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size_train,\n",
    "    shuffle=True,\n",
    "    pin_memory=pin_memory,\n",
    "    num_workers=num_workers\n",
    ")\n",
    "\n",
    "val_dataloader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=batch_size_val,\n",
    "    shuffle=False,\n",
    "    pin_memory=pin_memory,\n",
    "    num_workers=num_workers\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-27T23:22:55.520740400Z",
     "start_time": "2024-01-27T23:22:55.504780700Z"
    }
   },
   "id": "e93ae00195b1fe92"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2774bb9203d3e88e"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "def save_model(model, path):\n",
    "    torch.save(model.state_dict(), path)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-27T23:22:55.531708700Z",
     "start_time": "2024-01-27T23:22:55.519743300Z"
    }
   },
   "id": "cf0e695febb5627a"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "model = ViTMAEForPreTraining.from_pretrained(\"facebook/vit-mae-base\")\n",
    "model = model.to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-27T23:22:57.156028100Z",
     "start_time": "2024-01-27T23:22:55.532706300Z"
    }
   },
   "id": "2effd5039a6246ab"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-27T23:22:57.171107100Z",
     "start_time": "2024-01-27T23:22:57.160016800Z"
    }
   },
   "id": "3b15f0a5b3179aef"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "save_dir = r\"C:\\Internship\\ITMO_ML\\CTCI\\checkpoints\\vit\\vitmae_on_bubbles\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-27T23:22:57.191013500Z",
     "start_time": "2024-01-27T23:22:57.173059400Z"
    }
   },
   "id": "be3ef7b7d8b30212"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "def train(model, optimizer, train_dataloder, val_dataloader, num_epochs=5):\n",
    "    history = {\"train\": [], \"val\": []}\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"Epoch {epoch + 1}:\")\n",
    "        epoch_history = {\"train\": [], \"val\": []}\n",
    "        \n",
    "        model.train()\n",
    "        for inputs in tqdm(train_dataloder):\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            inputs = inputs.to(device)\n",
    "            batch_size, _, num_channels, height, width = inputs.data[\"pixel_values\"].shape\n",
    "            inputs.data[\"pixel_values\"] = torch.reshape(inputs.data[\"pixel_values\"], (batch_size, num_channels, height, width))\n",
    "            outputs = model(**inputs)\n",
    "            \n",
    "            loss = outputs.loss\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            history[\"train\"].append(loss.item())\n",
    "            epoch_history[\"train\"].append(loss.item())\n",
    "            \n",
    "        epoch_train_loss = sum(epoch_history[\"train\"])/len(epoch_history[\"train\"])\n",
    "        print(f\"Epoch train loss: {epoch_train_loss}\")\n",
    "        \n",
    "        model.eval()    \n",
    "        for inputs in tqdm(val_dataloader):\n",
    "            inputs = inputs.to(device)\n",
    "            batch_size, _, num_channels, height, width = inputs.data[\"pixel_values\"].shape\n",
    "            inputs.data[\"pixel_values\"] = torch.reshape(inputs.data[\"pixel_values\"], (batch_size, num_channels, height, width))\n",
    "            outputs = model(**inputs)\n",
    "            \n",
    "            loss = outputs.loss\n",
    "            \n",
    "            history[\"val\"].append(loss.item())\n",
    "            epoch_history[\"val\"].append(loss.item())\n",
    "    \n",
    "        epoch_val_loss = sum(epoch_history[\"val\"])/len(epoch_history[\"val\"])\n",
    "        print(f\"Epoch val loss: {epoch_val_loss}\\n\")\n",
    "        \n",
    "        save_model(model.to(\"cpu\"), path=os.path.join(save_dir, f\"epoch_{epoch+1}\"))\n",
    "        model = model.to(device)\n",
    "        \n",
    "    return history\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-27T23:22:57.204977Z",
     "start_time": "2024-01-27T23:22:57.189019400Z"
    }
   },
   "id": "1288e14c45f1fd46"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 195/195 [02:58<00:00,  1.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch train loss: 0.1625838197194613\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 11/22 [02:28<02:21, 12.82s/it]"
     ]
    }
   ],
   "source": [
    "history = train(\n",
    "    model=model,\n",
    "    optimizer=optimizer,\n",
    "    train_dataloder=train_dataloader,\n",
    "    val_dataloader=val_dataloader,\n",
    "    num_epochs=20\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2024-01-27T23:22:57.207969500Z"
    }
   },
   "id": "bd0fe0b5eb00256"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=2)\n",
    "fig.set_size_inches(18, 6)\n",
    "\n",
    "ax[0].plot(range(len(history[\"train\"])), history[\"train\"])\n",
    "ax[0].set_title(\"Train loss\")\n",
    "ax[1].plot(range(len(history[\"val\"])), history[\"val\"])\n",
    "ax[1].set_title(\"Val loss\")\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "d0a7ff04b97b098d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "28946ae22b9ef4c7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "2d4d80defe38ff10"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
